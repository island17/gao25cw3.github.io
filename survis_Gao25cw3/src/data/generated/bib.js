define({ entries : {
    "Bareh2025": {
        "abstract": "The study delves into the implications of Artificial Intelligence (AI), Large Language Model (LLM) adoption on qualitative research, particularly thematic synthesis, by using content analysis from multifaceted perspectives, i.e., the author\u2019s qualitative assessments and SWOT analysis. Utilising a systematic literature search, the author examines 65 AI-generated themes identified by the AI-LLM tool'ChatPDF' from 17 pieces of literature, focusing on context accuracy, textual patterns, review depth, inclusivity of sensitive topics, word counts, and SWOT analysis. Findings show a 56.92% context matching, which indicates a deeper and relevant insight into the AI-generated themes, thereby fostering thematic progression, and 89.23% non-repetitiveness in textual patterns, pointing to non-repetitive nature of the texts within the theme descriptions. Review depths vary, indicating diverse levels of In-depth, average, and surface-level review. 17 of the 65 AI-generated themes (26.15%) did not include sensitive topics, with only a handful of 4.61% addressing sensitive topics, which may generate biased themes. On the other hand, the SWOT analysis highlights ChatPDF's strengths in speedy interpretation, text summarisation, decent contextual accuracy, non-repetitive textual patterns, trend or gaps identification, translation feature, average word counts, improved research structure and opportunities like reducing researcher burnout, ease of adoption, conversational ability, connect concepts, enhanced methodologies, equitable access, and enhancing collaboration with the possibility to improve researcher\u2019s experience. However, it needs to improve contextual understanding, minor text repetitions, sensitive topic inclusion, statistical data extraction, potential algorithmic biases, privacy concerns, conversion of non-OCR PDF files, and transparency in its trained datasets. AI-LLMs offer improvements in qualitative research, specifically in thematic progression. Researchers can leverage LLMs for diverse theme elaboration and summarisation through multiple prompts. At the same time, AI developers must enhance their systems' contextual accuracy by flagging errors or bias, adapting to varied study types, and improving statistical data extraction. Higher educational institutions and publishers should have strong policies to validate AI-generated content and provide training for ethical adoption while protecting users' privacy. This study contributes significantly to researchers who intend to use LLM in qualitative research. It addresses the impact of LLM across all stakeholders, i.e., researchers, AI developers, educational institutions and publishers, while emphasising its ethical, transparent, and safe adoption. This study further advances the discussion on the ever-changing roles of AI-human collaboration in academic research.",
        "author": "Chanlang.Ki,Bareh",
        "doi": "10.1007/s43681-025-00730-8",
        "issn": "2730-5953",
        "journal": "AI and Ethics",
        "keywords": "type:Qualitative/Thematic Assessment, Artificial intelligence (AI), Large language model (LLM), ChatPDF, Qualitative analysis, AI ethical implication, SWOT analysis, Thematic review",
        "month": "4",
        "series": "Journal",
        "title": "A qualitative assessment of the accuracy of AI-LLM in academic research",
        "type": "article",
        "url": "https://link.springer.com/10.1007/s43681-025-00730-8",
        "year": "2025"
    },
    "Bennis2025": {
        "abstract": "Background: As part of qualitative research, the thematic analysis is time-consuming and technical. The rise of generative artificial intelligence (A.I.), especially large language models, has brought hope in enhancing and partly automating thematic analysis. Methods: The study assessed the relative efficacy of conventional against AI-assisted thematic analysis when investigating the psychosocial impact of cutaneous leishmaniasis (CL) scars. Four hundred forty-eight participant responses from a core study were analysed comparing nine A.I. generative models: Llama 3.1 405B, Claude 3.5 Sonnet, NotebookLM, Gemini 1.5 Advanced Ultra, ChatGPT o1-Pro, ChatGPT o1, GrokV2, DeepSeekV3, Gemini 2.0 Advanced with manual expert analysis. Jamovi software maintained methodological rigour through Cohen\u2019s Kappa coefficient calculations for concordance assessment and similarity measurement via Python using Jaccard index computations. Results: Advanced A.I. models showed impressive congruence with reference standards; some even had perfect concordance (Jaccard index",
        "author": "Issam,Bennis and Safwane,Mouwafaq",
        "doi": "10.1186/s12911-025-02961-5",
        "issn": "14726947",
        "issue": "1",
        "journal": "BMC Medical Informatics and Decision Making",
        "keywords": "type:Qualitative/Thematic Assessment, Artificial intelligence in qualitative research,Cutaneous leishmaniasis,Grounded theory development,Large language models,Natural language processing,Research automation,Thematic analysis",
        "month": "12",
        "pmid": "40065373",
        "publisher": "BioMed Central Ltd",
        "series": "Journal",
        "title": "Advancing AI-driven thematic analysis in qualitative research: a comparative study of nine generative models on Cutaneous Leishmaniasis data",
        "type": "article",
        "url": "https://link.springer.com/article/10.1186/s12911-025-02961-5",
        "volume": "25",
        "year": "2025"
    },
    "Guidotti2025": {
        "abstract": "With digital technology increasingly shaping the tourism industry, understanding customer sentiment and identifying key themes in reviews is crucial for enhancing service quality. However, traditional sentiment analysis and keyword extraction models typically demand significant time, computational resources, and labelled data for training. In this paper, we explore how Large Language Models (LLMs) can be leveraged to automatically classify reviews as positive or negative and extract relevant keywords without the need for dedicated training. Additionally, we frame the keyword extraction task as a tool to assist human users in comprehending and interpreting review content, especially in scenarios where ground truth labels for keywords are unavailable. To evaluate our approach, we conduct an experimental analysis using several datasets of tourism reviews and various LLMs. Our results demonstrate the reliability of LLMs as zero-shot classifiers for sentiment analysis and showcase the efficacy of the approach in extracting meaningful keywords from reviews, providing valuable insights into customer sentiments and preferences. Overall, this research contributes to the intersection of information technology and tourism by presenting a practical solution for sentiment analysis and keyword extraction in tourism reviews, leveraging the capabilities of LLMs as versatile tools for enhancing decision-making processes in the tourism industry.",
        "author": "Dario,Guidotti and Laura,Pandolfo and Luca,Pulina",
        "doi": "10.1007/s40558-024-00309-9",
        "issn": "19434294",
        "journal": "Information Technology and Tourism",
        "keywords": "type:Sentiment Analysis, AI for tourism,Keyword extraction,Natural language processing,Sentiment analysis",
        "month": "3",
        "publisher": "Springer Science and Business Media Deutschland GmbH",
        "series": "Journal",
        "title": "Discovering sentiment insights: streamlining tourism review analysis with Large Language Models",
        "type": "article",
        "url": "https://link.springer.com/article/10.1007/s40558-024-00309-9",
        "year": "2025"
    },
    "Liu2025": {
        "abstract": "Hospital admission interviews are critical for patient care but strain nurses\u2019 capacity due to time constraints and staffing shortages. While LLM-powered conversational agents (CAs) offer automation potential, their rigid sequencing and lack of humanized communication skills risk misunderstandings and incomplete data capture. Through participatory design with clinicians and volunteers, we identified essential communication strategies and developed a novel CA that implements these strategies through: (1) dynamic topic management using graph-based conversation flows, and (2) context-aware scaffolding with few-shot prompt tuning. Technical evaluation on an admission interview dataset showed our system achieving performance comparable to or surpassing human-written ground truth, while outperforming prompt-engineered baselines. A between-subject study (N",
        "author": "Dingdong,Liu and Yujing,Zhang and Bolin,Zhao and Shuai,Ma and Chuhan,Shi and Xiaojuan,Ma",
        "booktitle": "Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems",
        "city": "New York, NY, USA",
        "doi": "10.1145/3706598.3714196",
        "isbn": "9798400713941",
        "keywords": "type:Automatically Interview System, Online Social Networks, Data Collection, Thematic Analysis, InductiveCoding, Large Language Models (LLMs), ChatGPT, Google Gemini",
        "month": "4",
        "pages": "1-23",
        "publisher": "ACM",
        "series": "Conference",
        "title": "Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews",
        "type": "inproceedings",
        "url": "https://dl.acm.org/doi/10.1145/3706598.3714196",
        "year": "2025"
    },
    "Parker2024": {
        "abstract": "This paper assesses the potential for the large language models (LLMs) GPT-4 and GPT-3.5 to aid in deriving insight from education feedback surveys. Exploration of LLM use cases in education has focused on teaching and learning, with less exploration of capabilities in education feedback analysis. Survey analysis in education involves goals such as finding gaps in curricula or evaluating teachers, often requiring time-consuming manual processing of textual responses. LLMs have the potential to provide a flexible means of achieving these goals without specialized machine learning models or fine-tuning. We demonstrate a versatile approach to such goals by treating them as sequences of natural language processing (NLP) tasks including classification (multi-label, multi-class, and binary), extraction, thematic analysis, and sentiment analysis, each performed by LLM. We apply these workflows to a real-world dataset of 2500 end-of-course survey comments from biomedical science courses, and evaluate a zero-shot approach (i.e., requiring no examples or labeled training data) across all tasks, reflecting education settings, where labeled data is often scarce. By applying effective prompting practices, we achieve human-level performance on multiple tasks with GPT-4, enabling workflows necessary to achieve typical goals. We also show the potential of inspecting LLMs\u2019 chain-of-thought (CoT) reasoning for providing insight that may foster confidence in practice. Moreover, this study features development of a versatile set of classification categories, suitable for various course types (online, hybrid, or in-person) and amenable to customization. Our results suggest that LLMs can be used to derive a range of insights from survey text.",
        "author": "Michael J.,Parker and Caitlin,Anderson and Claire,Stone and YeaRim,Oh",
        "doi": "10.1007/s40593-024-00414-0",
        "issn": "15604306",
        "journal": "International Journal of Artificial Intelligence in Education",
        "keywords": "type:Qualitative/Thematic Assessment;Text Classification;Sentiment Analysis, ChatGPT,GPT-3.5,GPT-4,Large language model,Qualitative methodology,Survey analysis",
        "publisher": "Springer",
        "series": "Journal",
        "title": "A Large Language Model Approach to Educational Survey Feedback Analysis",
        "type": "article",
        "url": "https://link.springer.com/article/10.1007/s40593-024-00414-0",
        "year": "2024"
    },
    "Pasaribu2024": {
        "abstract": "The recruitment process usually requires a lot of resources and time. In the IT field, recruiters must also have domain knowledge in the IT field to be able to recruit well. Technological developments have given rise to various technologies that can help recruiters in the recruitment process. In the proposed approach, interviews are carried out by conducting interviews for each competency point given by the recruiter. Interviews consist of 2 stages, namely behavioral and technical. Behavioral interviews were conducted using BEI (Behavioral Event Interview) using the STAR (Situation, Task, Action, and Result) method. Behavioral and technical interview assessments are carried out using a 2-class classification. The results of the classification are aggregated to get a score for the whole interview. Few-shot learning was carried out on GPT-4o to generate interview questions. Evaluation with G-Eval on STAR question generation showed answerability metric score of 0.8938, listening metric score of 0.9633, relevance metric score of 0.986, and STAR completeness metric score of 0.9532. Interview evaluation or scoring was carried out by fine-tuning the Longformer model for behavioral interview assessment and few-shot learning on LLM GPT-4 for technical interview assessment. The use of RAG using GLiNER on a knowledge base containing knowledge about terms in the IT field is carried out to help augment the output of Longformer. The knowledge base used is Wikipedia. The data used in the fine-tuning process is synthetic data created with prompt engineering on GPT-4 and GPT-4o. The results of fine-tuning the Longformer model to classify behavioral interview results have an F1-score of 0.962, an accuracy value of 0.967, a precision value of 0.970, and a recall value of 0.967.",
        "author": "David K.H.,Pasaribu and Agung,Dewandaru and G. A.Putri,Saptawati",
        "booktitle": "Proceedings of 2024 IEEE International Conference on Data and Software Engineering: Data-Driven Innovation: Transforming Industries and Societies, ICoDSE 2024",
        "doi": "10.1109/ICODSE63307.2024.10829889",
        "isbn": "9798331506407",
        "keywords": "type:Automatically Interview System, GPT,IT talent,Large Language Model,few-shot,interview",
        "pages": "108-113",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "series": "Conference",
        "title": "Development of LLM-Based System for IT Talent Interview",
        "type": "inproceedings",
        "url": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp",
        "year": "2024"
    },
    "Qiao2025": {
        "abstract": "Thematic analysis (TA) is a widely used qualitative method foridentifying underlying meanings within unstructured text. How-ever, TA requires manual processes, which become increasinglylabour-intensive and time-consuming as datasets grow. While largelanguage models (LLMs) have been introduced to assist with TA onsmall-scale datasets, three key limitations hinder their effectiveness.First, current approaches often depend on interactions between anLLM agent and a human coder, a process that becomes challeng-ing with larger datasets. Second, with feedback from the humancoder, the LLM tends to mirror the human coder, which provides anarrower viewpoint of the data. Third, existing methods follow a se-quential process, where codes are generated for individual sampleswithout recalling previous codes and associated data, reducing theability to analyse data holistically. To address these limitations, wepropose Thematic-LM, an LLM-based multi-agent system for large-scale computational thematic analysis. Thematic-LM assigns spe-cialised tasks to each agent, such as coding, aggregating codes, andmaintaining and updating the codebook. We assign coder agentsdifferent identity perspectives to simulate the subjective nature ofTA, fostering a more diverse interpretation of the data. We appliedThematic-LM to the Dreaddit dataset and the Reddit climate changedataset to analyse themes related to social media stress and on-line opinions on climate change. We evaluate the resulting themesbased on trustworthiness principles in qualitative research. Ourstudy reveals insights such as assigning different identities to coderagents promotes divergence in codes and themes.",
        "author": "Tingrui,Qiao and Caroline,Walker and Chris,Cunningham and Yun.Sing,Koh",
        "booktitle": "Proceedings of the ACM on Web Conference 2025",
        "city": "New York, NY, USA",
        "doi": "10.1145/3696410.3714595",
        "isbn": "9798400712746",
        "keywords": "type:Qualitative/Thematic Assessment, Computational Social Science, Thematic Analysis, Large LanguageModel, Multi-agent System",
        "month": "4",
        "pages": "649-658",
        "publisher": "ACM",
        "series": "Conference",
        "title": "Thematic-LM: A LLM-based Multi-agent System for Large-scale Thematic Analysis",
        "type": "inproceedings",
        "url": "https://dl.acm.org/doi/10.1145/3696410.3714595",
        "year": "2025"
    },
    "Wang2025": {
        "abstract": "Large Language Models (LLMs) have gained attention in research and industry, aiming to streamline processes and enhance text analysis performance. Thematic Analysis (TA), a prevalent qualitative method for analyzing interview content, often requires at least two human experts to review and analyze data. This study demonstrates the feasibility of LLM-Assisted Thematic Analysis (LATA) using GPT-4 and Gemini. Specifically, we conducted semi-structured interviews with 14 researchers to gather insights on their experiences generating and analyzing Online Social Network (OSN) communications datasets. Following Braun and Clarke's six-phase TA framework with an inductive approach, we initially analyzed our interview transcripts with human experts. Subsequently, we iteratively designed prompts to guide LLMs through a similar process. We compare and discuss the manually analyzed outcomes with responses generated by LLMs and achieve a cosine similarity score up to 0.76, demonstrating a promising prospect for LATA. Additionally, the study delves into researchers' experiences navigating the complexities of collecting and analyzing OSN data, offering recommendations for future research and application designers.",
        "author": "Qile,Wang and Moath,Erqsous and Kenneth E.,Barner and Matthew Louis,Mauriello",
        "doi": "10.1145/3711022",
        "issn": "2573-0142",
        "issue": "2",
        "journal": "Proceedings of the ACM on Human-Computer Interaction",
        "keywords": "type:Qualitative/Thematic Assessment, Online Social Networks, Data Collection, Thematic Analysis, Inductive Coding, Large Language Models (LLMs), ChatGPT, Google Gemini",
        "month": "5",
        "pages": "1-28",
        "series": "Conference",
        "title": "LATA: A Pilot Study on LLM-Assisted Thematic Analysis of Online Social Network Data Generation Experiences",
        "type": "article",
        "url": "https://dl.acm.org/doi/10.1145/3711022",
        "volume": "9",
        "year": "2025"
    },
    "Xiao2023": {
        "abstract": "Qualitative analysis of textual contents unpacks rich and valuable information by assigning labels to the data. However, this process is often labor-intensive, particularly when working with large datasets. While recent AI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let alone be challenged by the limited generalizability of those task-specific models. In this study, we explored the use of large language models (LLMs) in supporting deductive coding, a major category of qualitative analysis where researchers use pre-determined codebooks to label the data into a fixed set of codes. Instead of training task-specific models, a pre-trained LLM could be used directly for various tasks without fine-tuning through prompt learning. Using a curiosity-driven questions coding task as a case study, we found, by combining GPT-3 with expert-drafted codebooks, our proposed approach achieved fair to substantial agreements with expert-coded results. We lay out challenges and opportunities in using LLMs to support qualitative coding and beyond.",
        "author": "Ziang,Xiao and Xingdi,Yuan and Q. Vera,Liao and Rania,Abdelghani and Pierre.Yves,Oudeyer",
        "booktitle": "28th International Conference on Intelligent User Interfaces, Proceedings IUI",
        "doi": "10.1145/3581754.3584136",
        "isbn": "9798400701078",
        "keywords": "type:Qualitative/Thematic Assessment, Deductive Coding,GPT-3,Large Language Model,Qualitative Analysis",
        "month": "3",
        "pages": "75-78",
        "publisher": "Association for Computing Machinery",
        "series": "Conference",
        "title": "Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding",
        "type": "inproceedings",
        "url": "https://dl.acm.org/doi/epdf/10.1145/3581754.3584136",
        "year": "2023"
    },
    "Zhong2024": {
        "abstract": "This paper introduces an innovative semi-supervised learning approach for text classification, addressing the challenge of abundant data but limited labeled examples. Our methodology integrates few-shot learning with retrieval-augmented generation (RAG) and conventional statistical clustering, enabling effective learning from a minimal number of labeled instances while generating high-quality labeled data. To the best of our knowledge, we are the first to incorporate RAG alongside clustering in text data generation. Our experiments on the Reuters and Web of Science datasets demonstrate state-of-the-art performance, with few-shot augmented data alone producing results nearly equivalent to those achieved with fully labeled datasets. Notably, accuracies of 95.41\\% and 82.43\\% were achieved for complex text document classification tasks, where the number of categories can exceed 100.",
        "author": "Shan,Zhong and Jiahao,Zeng and Yongxin,Yu and Bohong,Lin",
        "doi": "10.1007/s41060-025-00774-3",
        "issn": "23644168",
        "journal": "International Journal of Data Science and Analytics",
        "keywords": "type:Text Classification, Data Augmentation, Clustering, SSTC, LLMs",
        "month": "11",
        "series": "Journal",
        "title": "Clustering Algorithms and RAG Enhancing Semi-Supervised Text Classification with Large LLMs",
        "type": "article",
        "url": "http://arxiv.org/abs/2411.06175",
        "year": "2024"
    }
}});